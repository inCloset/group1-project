{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multicomp as multi\n",
    "import scipy.stats\n",
    "import seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# # Fetch dataset\n",
    "wine_quality = pd.read_csv('https://archive.ics.uci.edu/static/public/186/data.csv')\n",
    "\n",
    "# Access the data and convert it to a DataFrame\n",
    "display(wine_quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split wine data set to red and white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into red and white color\n",
    "red_wine = wine_quality[wine_quality['color'] == 'red']\n",
    "white_wine = wine_quality[wine_quality['color'] == 'white']\n",
    "display(red_wine)\n",
    "display(white_wine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(functionToCall):\n",
    "    print('\\nRed Wine\\n')\n",
    "    functionToCall(red_wine)\n",
    "    print('\\nWhite Wine\\n')\n",
    "    functionToCall(white_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm(wine_set):\n",
    "    wine_set.columns = [x.strip().replace(' ','_') for x in wine_set.columns]\n",
    "call(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categ_quality(wine_set):\n",
    "    low = wine_set[wine_set['quality'] <= 5]\n",
    "    medium = wine_set[(wine_set['quality'] == 6) | (wine_set['quality'] == 7)]\n",
    "    high = wine_set[wine_set['quality'] > 7]\n",
    "    \n",
    "    low['quality_mark'] = 'low'\n",
    "    medium['quality_mark'] = 'medium'\n",
    "    high['quality_mark'] = 'high'\n",
    "    \n",
    "    frames = [low, medium, high]\n",
    "    return pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the F-statistics and associated p-value\n",
    "def anova(wine_set):\n",
    "    prepared_data = add_categ_quality(wine_set)\n",
    "    model1 = smf.ols(formula='total_sulfur_dioxide ~ C(quality_mark)', data = prepared_data)\n",
    "    results1 = model1.fit()\n",
    "    print(results1.summary())\n",
    "    \n",
    "    sub = prepared_data[['total_sulfur_dioxide', 'quality_mark']]\n",
    "    print(\"\\nMeans for total sulfur dioxide by quality marks of wine \\n\")\n",
    "    print(sub.groupby('quality_mark').mean())\n",
    "    print('\\nStandard deviation for total sulfur dioxide by quality marks of wine \\n')\n",
    "    print(sub.groupby('quality_mark').std(), '\\n')\n",
    "    \n",
    "    # Perform Post hoc test\n",
    "    mc1 = multi.MultiComparison(sub['total_sulfur_dioxide'], sub['quality_mark'])\n",
    "    res1 = mc1.tukeyhsd()\n",
    "    print(res1.summary())\n",
    "    \n",
    "call(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plt.figure(figsize=(10,6))\n",
    "seaborn.boxplot(x='quality', y='total_sulfur_dioxide', hue='color', data=wine_quality, palette='hsv')\n",
    "plt.title('Total sulfur dioxide in wine by quality and color')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "seaborn.boxplot(x='quality', y='alcohol', hue='color', data=wine_quality, palette='hsv')\n",
    "plt.title('Alcohol in wine by quality and color')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "seaborn.boxplot(x='quality', y='citric_acid', hue='color', data=wine_quality, palette='hsv')\n",
    "plt.title('Citric Acid in wine by quality and color')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "seaborn.boxplot(x='quality', y='volatile_acidity', hue='color', data=wine_quality, palette='hsv')\n",
    "plt.title('Volatile Acidity in wine by quality and color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "seaborn.boxplot(x='quality', y='residual_sugar', hue='color', data=wine_quality, palette='hsv')\n",
    "plt.title('Residual Sugar in wine by quality and color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix\n",
    "### Positive\n",
    "### Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the quality_mark and color columns and construct a correlation matrix between the remaining columns\n",
    "wine_quality_drop = wine_quality.drop(['color'], axis=1)\n",
    "correration = wine_quality_drop.corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "seaborn.heatmap(correration, cbar=True, square=True, fmt='.1f', annot=True, annot_kws={'size':8}, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(wine_set):\n",
    "    scat1 = seaborn.regplot(x = \"density\", y = \"residual_sugar\", fit_reg = True, data = wine_set)\n",
    "    plt.xlabel(\"Density of wine\")\n",
    "    plt.ylabel(\"Residual sugar in wine, gram\")\n",
    "    plt.title(\"Association between wine's density and residual sugar \\n\")\n",
    "    plt.show()\n",
    "\n",
    "    print(scipy.stats.pearsonr(wine_set['density'], wine_set[\"residual_sugar\"]))\n",
    "\n",
    "call(pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring Statistical Interactions\n",
    "def explore(wine_set):\n",
    "    low = wine_set[wine_set['quality'] <= 5]\n",
    "    medium = wine_set[(wine_set['quality'] == 6) | (wine_set['quality'] == 7)]\n",
    "    high = wine_set[wine_set['quality'] > 7]\n",
    "\n",
    "    print('association between wine`s density and residual sugar for wines \\nof `low` quality')\n",
    "    print(scipy.stats.pearsonr(low['density'], low[\"residual_sugar\"]))\n",
    "    print('\\nof `medium` quality')\n",
    "    print(scipy.stats.pearsonr(medium['density'], medium[\"residual_sugar\"]))\n",
    "    print('\\nof `high` quality')\n",
    "    print(scipy.stats.pearsonr(high['density'], high[\"residual_sugar\"]))\n",
    "\n",
    "    scat0 = seaborn.regplot(x=\"density\", y=\"residual_sugar\", fit_reg=True, data=low)\n",
    "    plt.xlabel(\"Density of wine\")\n",
    "    plt.ylabel(\"Residual sugar in wine, gram\")\n",
    "    plt.title(\"Association between wine's density and residual sugar for wines of `low` quality\")\n",
    "    plt.show()\n",
    "\n",
    "    scat0 = seaborn.regplot(x=\"density\", y=\"residual_sugar\", fit_reg=True, data=medium)\n",
    "    plt.xlabel(\"Density of wine\")\n",
    "    plt.ylabel(\"Residual sugar in wine, gram\")\n",
    "    plt.title(\"Association between wine's density and residual sugar for wines of `medium` quality\")\n",
    "    plt.show()\n",
    "\n",
    "    scat0 = seaborn.regplot(x=\"density\", y=\"residual_sugar\", fit_reg=True, data=high)\n",
    "    plt.xlabel(\"Density of wine\")\n",
    "    plt.ylabel(\"Residual sugar in wine, gram\")\n",
    "    plt.title(\"Association between wine's density and residual sugar for wines of `high` quality\\n\")\n",
    "    plt.show()\n",
    "\n",
    "call(explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print frequency distributions of wines' quality \n",
    "def frequencyDists(wine_set):\n",
    "    print(\"This is the frequency distribution of the wines' quality.\")\n",
    "    print(wine_set.groupby(\"quality\").size()*100 / len(wine_set))\n",
    "    print()\n",
    "\n",
    "call(frequencyDists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print quartile split of the quality variable \n",
    "def quartileSplit(wine_set):\n",
    "    print(\"This is the quartile split of the wines' quality. I-st column contains the intervals of wines' quality;\")\n",
    "    print(\"II-nd - the number of wine samples with the quality in the corresponding interval.\")\n",
    "    wine_set[\"quality_quart\"] = pd.qcut(wine_set[\"quality\"], 3)\n",
    "    print(wine_set.groupby(\"quality_quart\").size())\n",
    "\n",
    "call(quartileSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the how the number of wine quality level is distributed and visualized with countplots and factorplots \n",
    "def countplots(wine_set):\n",
    "    wine_set[\"quality\"] = pd.Categorical(wine_set[\"quality\"])\n",
    "    seaborn.countplot(x=\"quality\", data=wine_set)\n",
    "    plt.xlabel(\"Quality level of wine (0-10 scale)\")\n",
    "    plt.show()\n",
    "\n",
    "call(countplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the alcohol percent in each level of quality of wine using catplot\n",
    "def catplot(wine_set):\n",
    "    seaborn.catplot(x=\"quality\", y=\"alcohol\", data=wine_set, kind=\"strip\")\n",
    "    plt.xlabel(\"Quality level of wine, 0-10 scale\")\n",
    "    plt.ylabel(\"Alcohol level in wine, % ABV\")\n",
    "    if wine_set.equals(red_wine):\n",
    "        plt.title(\"Alcohol percent in each level of red wine's quality\")\n",
    "    else:\n",
    "        plt.title(\"Alcohol percent in each level of white wine's quality\")\n",
    "    plt.show()\n",
    "\n",
    "call(catplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multicomp as multi\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression(wine_set):\n",
    "    # local variable to identify if the wine_set red or white\n",
    "    w = wine_set\n",
    "\n",
    "\n",
    "    # recode quality (response variable) into 2 groups: 0:{3,4,5}, 1:{6,7,8,9}\n",
    "    recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "    wine_set['quality_c'] = wine_set['quality'].map(recode)\n",
    "\n",
    "\n",
    "    # split into training and testing sets\n",
    "    predictors = wine_set[[\"sulphates\", 'alcohol']]\n",
    "    targets = wine_set.quality_c\n",
    "\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.4)\n",
    "\n",
    "    # build model on training data\n",
    "    classifier = LogisticRegression()\n",
    "    classifier = classifier.fit(pred_train, tar_train)\n",
    "\n",
    "    predictions = classifier.predict(pred_test)\n",
    "\n",
    "     # print the confusion matrix and accuracy of the model\n",
    "    print('Confusion Matrix:\\n',sklearn.metrics.confusion_matrix(tar_test, predictions))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(tar_test, predictions))\n",
    "    \n",
    "    print ('Score:', classifier.score(pred_test, tar_test))\n",
    "    print ('RMSE:', mean_squared_error(predictions, tar_test) ** 0.5)\n",
    "\n",
    "print('----------------Logistic Regression------------------------')\n",
    "call(log_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decis_tree(wine_set):\n",
    "    # local variable to identify if the wine_set red or white\n",
    "    w = wine_set\n",
    "\n",
    "\n",
    "    # recode quality (response variable) into 2 groups: 0:{3,4,5}, 1:{6,7,8,9}\n",
    "    recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "    wine_set['quality_c'] = wine_set['quality'].map(recode)\n",
    "\n",
    "\n",
    "    # split into training and testing sets\n",
    "    predictors = wine_set[[\"residual_sugar\", 'alcohol']]\n",
    "    targets = wine_set.quality_c\n",
    "\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.4)\n",
    "\n",
    "    # build model on training data\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier = classifier.fit(pred_train, tar_train)\n",
    "\n",
    "    predictions = classifier.predict(pred_test)\n",
    "\n",
    "     # print the confusion matrix and accuracy of the model\n",
    "    print('Confusion Matrix:\\n',sklearn.metrics.confusion_matrix(tar_test, predictions))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(tar_test, predictions))\n",
    "    \n",
    "    print ('Score:', classifier.score(pred_test, tar_test))\n",
    "    print ('RMSE:', mean_squared_error(predictions, tar_test) ** 0.5)\n",
    "\n",
    "print('----------------Decision Tree------------------------')\n",
    "call(decis_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(wine_set):\n",
    "    \n",
    "    # recode quality (response variable) into 2 groups: 0:{3,4,5}, 1:{6,7,8,9}\n",
    "    recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "    wine_set['quality_c'] = wine_set['quality'].map(recode)\n",
    "\n",
    "    # split into training and testing sets\n",
    "    predictors = wine_set[[\"residual_sugar\", 'alcohol']]\n",
    "    targets = wine_set.quality_c\n",
    "\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.4)\n",
    "    \n",
    "    \n",
    "    # build model on training data\n",
    "    classifier = KNeighborsClassifier()\n",
    "    classifier = classifier.fit(pred_train, tar_train)\n",
    "\n",
    "    predictions = classifier.predict(pred_test)\n",
    "\n",
    "    # print the confusion matrix and accuracy of the model\n",
    "    print('Confusion Matrix:\\n',sklearn.metrics.confusion_matrix(tar_test, predictions))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(tar_test, predictions))\n",
    "    \n",
    "    print ('Score:', classifier.score(pred_test, tar_test))\n",
    "    print ('RMSE:', mean_squared_error(predictions, tar_test) ** 0.5)\n",
    "\n",
    "    \n",
    "print('----------------KNN------------------------')\n",
    "call(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(wine_set):\n",
    "   \n",
    "    # recode quality (response variable) into 2 groups: 0:{3,4,5}, 1:{6,7,8,9}\n",
    "    recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "    wine_set['quality_c'] = wine_set['quality'].map(recode)\n",
    "\n",
    "    # split into training and testing sets\n",
    "    predictors = wine_set[[\"density\", 'alcohol', 'sulphates', 'pH', 'volatile_acidity', 'chlorides', 'fixed_acidity',\n",
    "                           'citric_acid', 'residual_sugar', 'free_sulfur_dioxide', 'total_sulfur_dioxide']]\n",
    "    targets = wine_set.quality_c\n",
    "\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.4)\n",
    "    \n",
    "\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(pred_train, tar_train)\n",
    "    predictionsG = classifier.predict(pred_test)\n",
    "    # print the confusion matrix and accuracy of the model\n",
    "    print('Confusion Matrix:\\n',sklearn.metrics.confusion_matrix(tar_test, predictionsG))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(tar_test, predictionsG))\n",
    "    print(\"Gaus:\" + str(classifier.score(pred_test, tar_test)))\n",
    "    mse = mean_squared_error(predictionsG, tar_test)\n",
    "    print('MSE:',mse ** 0.5)\n",
    "\n",
    "    classifierm = MultinomialNB()\n",
    "    classifierm.fit(pred_train, tar_train)\n",
    "    predictionsM = classifierm.predict(pred_test)\n",
    "    # print the confusion matrix and accuracy of the model\n",
    "    print('\\nConfusion Matrix:\\n',sklearn.metrics.confusion_matrix(tar_test, predictionsM))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(tar_test, predictionsM))\n",
    "    print(\"Multi:\" + str(classifierm.score(pred_test, tar_test)))\n",
    "    mse = mean_squared_error(predictionsM, tar_test)\n",
    "    print('MSE:',mse ** 0.5)\n",
    "\n",
    "    classifierb = BernoulliNB()\n",
    "    classifierb.fit(pred_train, tar_train)\n",
    "    predictionsB = classifierb.predict(pred_test)\n",
    "    # print the confusion matrix and accuracy of the model\n",
    "    print('\\nConfusion Matrix:\\n',sklearn.metrics.confusion_matrix(tar_test, predictionsB))\n",
    "    print('Accuracy:',sklearn.metrics.accuracy_score(tar_test, predictionsB))\n",
    "    print(\"Bernoulli:\" + str(classifierb.score(pred_test, tar_test)))\n",
    "    mse = mean_squared_error(predictionsB, tar_test)\n",
    "    print('MSE:',mse ** 0.5)\n",
    "    \n",
    "\n",
    "print('----------------Naive Bayes------------------------')\n",
    "call(naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forests(wine_set):\n",
    "    # recode quality (response variable) into 2 groups: 0:{3,4,5}, 1:{6,7,8,9}\n",
    "    recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "    wine_set['quality_c'] = wine_set['quality'].map(recode)\n",
    "\n",
    "    # split into training and testing sets\n",
    "    predictors = wine_set[[\"density\", 'alcohol', 'sulphates', 'pH', 'volatile_acidity', 'chlorides', 'fixed_acidity',\n",
    "                           'citric_acid', 'residual_sugar', 'free_sulfur_dioxide', 'total_sulfur_dioxide']]\n",
    "\n",
    "    targets = wine_set.quality_c\n",
    "\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.4)\n",
    "\n",
    "    # build model on training data#\n",
    "    classifier = RandomForestClassifier(n_estimators=25)\n",
    "    classifier = classifier.fit(pred_train, tar_train)\n",
    "\n",
    "    predictions = classifier.predict(pred_test)\n",
    "    # print the confusion matrix and accuracy of the model\n",
    "    print('Confusion matrix:\\n', sklearn.metrics.confusion_matrix(tar_test, predictions))\n",
    "    print('Accuracy:', sklearn.metrics.accuracy_score(tar_test, predictions))\n",
    "\n",
    "    # to display the relative importance of each predictive variable\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(pred_train, tar_train)\n",
    "\n",
    "    print('\\nImportance of predictors:')\n",
    "    dct = dict()\n",
    "    for c in range(len(predictors.columns)):\n",
    "        dct[predictors.columns[c]] = model.feature_importances_[c]\n",
    "    print(sorted(dct.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "    # run different numbers of trees to see the effect of the number on the accuracy of the prediction\n",
    "    n = 100\n",
    "    accuracy = [0]*n\n",
    "\n",
    "    for i in range(n):\n",
    "        classifier = RandomForestClassifier(n_estimators=i+1, random_state=42)\n",
    "        classifier = classifier.fit(pred_train, tar_train)\n",
    "        predictions = classifier.predict(pred_test)\n",
    "        accuracy[i] = sklearn.metrics.accuracy_score(tar_test, predictions)\n",
    "\n",
    "    plt.plot(range(1, n+1), accuracy)\n",
    "    plt.xlabel(\"Number of trees\")\n",
    "    plt.ylabel(\"Accuracy of prediction\")\n",
    "    plt.title(\"Effect of the number of trees on the prediction accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    print(accuracy)\n",
    "\n",
    "print('----------------Random Forests------------------------')\n",
    "call(random_forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regr(wine_set):\n",
    "\n",
    "    pred = wine_set[[\"density\", 'alcohol', 'sulphates', 'pH', 'volatile_acidity', 'chlorides', 'fixed_acidity',\n",
    "                    'citric_acid', 'residual_sugar', 'free_sulfur_dioxide', 'total_sulfur_dioxide']]\n",
    "    predictors = pred.copy()\n",
    "    targets = wine_set.quality\n",
    "\n",
    "    # standardize predictors to have mean=0 and sd=1\n",
    "    predictors = pd.DataFrame(preprocessing.scale(predictors))\n",
    "    predictors.columns = pred.columns\n",
    "    # print(predictors.head())\n",
    "\n",
    "    # split into training and testing sets\n",
    "    pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, targets, test_size=.3, random_state=123)\n",
    "\n",
    "    # specify the lasso regression model\n",
    "    model = LassoLarsCV(cv=10, precompute=False).fit(pred_train, tar_train)\n",
    "\n",
    "    print('Predictors and their regression coefficients:')\n",
    "    d = dict(zip(predictors.columns, model.coef_))\n",
    "    for k in d:\n",
    "        print(k, ':', d[k])\n",
    "\n",
    "    # plot coefficient progression\n",
    "    m_log_alphas = -np.log10(model.alphas_)\n",
    "    # ax = plt.gca()\n",
    "    plt.plot(m_log_alphas, model.coef_path_.T)\n",
    "    print('\\nAlpha:', model.alpha_)\n",
    "    plt.axvline(-np.log10(model.alpha_), linestyle=\"dashed\", color='k', label='alpha CV')\n",
    "    plt.ylabel(\"Regression coefficients\")\n",
    "    plt.xlabel(\"-log(alpha)\")\n",
    "    plt.title('Regression coefficients progression for Lasso paths')\n",
    "    plt.show()\n",
    "\n",
    "    # plot mean squared error for each fold\n",
    "    m_log_alphascv = -np.log10(model.cv_alphas_)\n",
    "    plt.plot(m_log_alphascv, model.mse_path_, ':')\n",
    "    plt.plot(m_log_alphascv, model.mse_path_.mean(axis=-1), 'k', label='Average across the folds', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('Mean squared error')\n",
    "    plt.title('Mean squared error on each fold')\n",
    "    plt.show()\n",
    "\n",
    "    # Mean squared error from training and test data\n",
    "    train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "    test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
    "    print('\\nMean squared error for training data:', train_error)\n",
    "    print('Mean squared error for test data:', test_error)\n",
    "\n",
    "    rsquared_train = model.score(pred_train, tar_train)\n",
    "    rsquared_test = model.score(pred_test, tar_test)\n",
    "    print('\\nR-square for training data:', rsquared_train)\n",
    "    print('R-square for test data:', rsquared_test)\n",
    "#\n",
    "print('----------------Lasso Regression------------------------')\n",
    "call(lasso_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_linear(wine_set):\n",
    "     # recode quality into 2 groups: 0:{3,4,5,6}, 1:{7,8,9}\n",
    "    recode = {3: 0, 4: 0, 5:0, 6:0, 7:1, 8:1, 9:1}\n",
    "    wine_set['quality_c'] = wine_set['quality'].map(recode)\n",
    "    scat0 = seaborn.regplot(x=\"volatile_acidity\", y=\"quality_c\", fit_reg=True, data=wine_set)\n",
    "    plt.xlabel(\"Amount of volatile acidity in wine\")\n",
    "    plt.ylabel(\"Quality level of wine (0-10 scale)\")\n",
    "    plt.title(\"Association between the amount of volatile acidity in wine and the quality of wine\")\n",
    "    plt.show()\n",
    "\n",
    "    # centering the explanatory variable by subrtacting the mean\n",
    "    f_acidity_mean = wine_set[\"volatile_acidity\"].mean()\n",
    "    print(\"mean of the volatile acidity variable = \", f_acidity_mean)\n",
    "    wine_set[\"volatile_acidity\"] = wine_set[\"volatile_acidity\"] - f_acidity_mean\n",
    "    print(\"mean of the volatile acidity variable after normalization = \", wine_set[\"volatile_acidity\"].mean())\n",
    "\n",
    "    print (\"\\nOLS regression model for the association between the amount of volatile acidity in wine and the quality of wine:\")\n",
    "    model1 = smf.ols(formula=\"quality_c ~ volatile_acidity\", data=wine_set)\n",
    "    results1 = model1.fit()\n",
    "    print(results1.summary())\n",
    "\n",
    "\n",
    "call(basic_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model is best modality to use make predictions on red/white wine quality\n",
    "### Ans: based on all the modality that we ran, Random Forest appears to be the best modality to use to make predictions of wine quality, with an accuracy of 85% predicting red wine quality while white wine prediction is at 83%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random forests to predict the quality of wine\n",
    "# split the data into features and target for red wine\n",
    "recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "red_wine['quality_c'] = red_wine['quality'].map(recode)\n",
    "display(red_wine)\n",
    "        \n",
    "X_red = red_wine.drop(columns=['color', 'quality', 'quality_quart', 'quality_c'])\n",
    "y_red = red_wine['quality_c']\n",
    "\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_red, y_red, test_size=0.2, random_state=3)\n",
    "print(X_train_red.shape, X_test_red.shape, y_train_red.shape, y_test_red.shape)\n",
    "\n",
    "red_wine_model = RandomForestClassifier(n_estimators=100, random_state=3)\n",
    "red_wine_model.fit(X_train_red, y_train_red)\n",
    "y_test_pred_red = red_wine_model.predict(X_test_red)\n",
    "test_data_accuracy_red = accuracy_score(y_test_pred_red, y_test_red)\n",
    "print('Red Wine Accuracy:', round(test_data_accuracy_red, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random forests to predict the quality of wine\n",
    "# split the data into features and target for red wine\n",
    "display(white_wine)\n",
    "recode = {3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1}\n",
    "white_wine['quality_c'] = white_wine['quality'].map(recode)\n",
    "display(red_wine)\n",
    "X_white = white_wine.drop(columns=['color', 'quality', 'quality_quart', 'quality_c'])\n",
    "y_white = white_wine['quality_c']\n",
    "\n",
    "X_train_white, X_test_white, y_train_white, y_test_white = train_test_split(X_white, y_white, test_size=0.2, random_state=3)\n",
    "print(X_train_white.shape, X_test_white.shape, y_train_white.shape, y_test_white.shape)\n",
    "\n",
    "white_wine_model = RandomForestClassifier(n_estimators=100, random_state=3)\n",
    "white_wine_model.fit(X_train_white, y_train_white)\n",
    "y_test_pred_white = white_wine_model.predict(X_test_white)\n",
    "test_data_accuracy_white = accuracy_score(y_test_pred_white, y_test_white)\n",
    "print('White Wine Accuracy:', round(test_data_accuracy_white, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are using a random input data from the red data set to test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_input_data = [[7.4, 0.7, 0, 1.9, 0.076, 11, 34, 0.9978, 3.51, 0.56, 9.4]]\n",
    "red_input_data_as_np = np.array(red_input_data)\n",
    "red_input_data_as_np = red_input_data_as_np.reshape(1, -1)\n",
    "red_pred = red_wine_model.predict(red_input_data_as_np)\n",
    "if red_pred == 0:\n",
    "    print('Red Wine Quality: Low') \n",
    "else:\n",
    "    print('Red Wine Quality: High')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are using a random input data from the white data set to test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_input_data = [[6.3, 0.30, 0.34, 1.6,0.049, 14.0, 132.0, 0.99400, 3.30, 0.49, 9.5]]\n",
    "white_input_data_as_np = np.array(white_input_data)\n",
    "white_input_data_as_np = white_input_data_as_np.reshape(1, -1)\n",
    "white_pred = white_wine_model.predict(white_input_data_as_np)\n",
    "if white_pred == 0:\n",
    "    print('White Wine Quality: Low') \n",
    "else:\n",
    "    print('White Wine Quality: High')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
